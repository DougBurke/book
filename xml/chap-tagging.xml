<?xml version="1.0" encoding="UTF-8"?>
<?oxygen RNGSchema="http://www.oasis-open.org/docbook/xml/5.0/rng/docbookxi.rng" type="xml"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="chap-tagging">
    <title>Part of speech tagging</title>
    <sect1 xml:id="sec-tagging-intro">
        <title>Introduction</title>
        <para>In the last episode, you have seen how n-gram language models can be used to model
            structure of language, purely based on words. In this chapter, we will make a further
            abstraction and will try to find proper <emphasis role="italic">part of speech
                tags</emphasis> (also named <emphasis role="italic">morphosyntactic tags</emphasis>)
            for words. Part of speech tags give relevant information about the role of a word in its
            narrow context. It may also provide information about the inflection of a word. POS tags
            are a valuable part of a language processing pipeline, they provide useful information
            to other components such as a parser or a named-entity recognizer.</para>
        <para>There is no such thing as a standard set of part of speech tags (let's call them 'POS
            tags' from now on). Just like programming languages, text editors, and operating
            systems, the tag set that people use depends on the task at hand and taste. For our
            purposes, we will use the Brown tag set<footnote>
                <para>A full description of the Brown tag set can be found at: <link
                        xlink:href="http://www.scs.leeds.ac.uk/ccalas/tagsets/brown.html"
                        >http://www.scs.leeds.ac.uk/ccalas/tagsets/brown.html</link></para>
            </footnote>.</para>
        <para>This is a sentence from the Brown corpus that is annotated with tags:</para>
        <para><emphasis role="italic">A/AT similar/JJ resolution/NN passed/VBD in/IN the/AT
                Senate/NN by/IN a/AT vote/NN of/IN 29-5/CD ./.</emphasis></para>
        <para>The notation here is very simple: as our previous fragments of the Brown corpus the
            sentence is pre-tokenized. However, each word is amended by a POS tag that indicate the
            role of the world. For instance, the word 'a' is an <emphasis role="italic"
                >article</emphasis>, 'similar' an <emphasis role="italic">adjective</emphasis>, and
            'resolution' a <emphasis role="italic">singular common noun</emphasis>.</para>
        <para>Corpora, such as the Brown corpus only provide POS tags for a small amount of
            sentences that occur in corpus. Being a working programmer, you will deal with new data
            that does not occur in the Brown corpus. Now, wouldn't it be nice to have a set of
            functions that could add POS tags to untagged data? Software that performs this task is
            called a POS tagger or morphosyntactic tagger, and this is exactly the thing we will
            build in this chapter.</para>
        <sect2>
            <title>Exercises</title>
            <itemizedlist>
                <listitem>
                    <para>In the data provided with this book, you will find the file
                            <filename>brown-pos-train.txt</filename>. Open this file with a text
                        file viewer or text editor, and look at the five first sentences. Try to
                        find out what the tags mean using the description of the Brown tag
                        set.</para>
                </listitem>
            </itemizedlist>
        </sect2>
    </sect1>
    <sect1 xml:id="sec-tagging-frequency">
        <title>Frequency-based tagging</title>
        <para>In one of the simplest forms of tagging, we just assign the most frequent POS tag for
            a token in the training data to a token in untagged data. That's right, the most
            frequent tag, because a token can have more than one tag. Consider the following two
            sentences:</para>
        <itemizedlist>
            <listitem>
                <para>I wouldn't <emphasis role="bold">trust</emphasis> him.</para>
            </listitem>
            <listitem>
                <para>He put money in the family <emphasis role="bold">trust</emphasis>.</para>
            </listitem>
        </itemizedlist>
        <para>Both sentences contain the word 'trust'. However, 'trust' has different roles in
            different roles in both sentences. In the first sentence 'trust' is a verb, in the
            second sentence it is a noun. So, for many tokens we will have the choice of multiple
            tags. If we tag the token with the most frequent tag, we will frequently tag tokens
            incorrectly, but it is a first step.</para>
        <para>To ease handling of tokens and tags, we will make type aliases for tokens and tags and
            define a new datatype for training instances, aptly named <emphasis role="italic"
                >TrainingInstance</emphasis>:<programlisting>type Token = String
type Tag = String

data TrainingInstance = TrainingInstance Token Tag
                        deriving Show</programlisting></para>
        <para>The <emphasis role="italic">Token</emphasis> and <emphasis role="italic"
                >Tag</emphasis> aliases will allow us to write clean function signatures. The
                <emphasis role="italic">TrainingInstance</emphasis> data type has only one
            constructor, <emphasis role="italic">TrainingInstance</emphasis>. The data type derives
            from the <emphasis role="italic">Show</emphasis> typeclass, which allows us to get a
                <emphasis role="italic">String</emphasis> representation of an instance<footnote>
                <para>This <emphasis role="italic">String</emphasis> representation is also used by
                        <command>ghci</command> to print the value of a <emphasis role="italic"
                        >TrainingInstance</emphasis>.</para>
            </footnote>. We can use this constructor to create training
            instances:<screen>*Main> <userinput>TrainingInstance "the" "AT"</userinput>
TrainingInstance "the" "AT"
*Main> <userinput>TrainingInstance "pony" "NN"</userinput>
TrainingInstance "pony" "NN"</screen></para>
        <para>Since our first POS tagger is trained purely on tokens and tags, and requires no
            sentencial information, the corpus will be represented as a list of <emphasis
                role="italic">TrainingInstance</emphasis>. Since we can use the <emphasis
                role="italic">words</emphasis> function to tokenize the corpus, the task at hand is
            to convert a list of strings of the format "token/tag" to a list of <emphasis
                role="italic">TrainingInstance</emphasis>. This is done by splitting the <emphasis
                role="italic">String</emphasis> on the forward slash character (/). We can use the
                <function>break</function> function to break the string on the first element for
            which the supplied function is true. For
            instance:<screen>Prelude> <userinput>break (== '/') "the/AT"</userinput>
("the","/AT")</screen></para>
        <para>This is a good start, we would only have to chop off the first character of the second
            element in the tuple. However, there is another problem: although a tag can never
            contain a slash, a token can. Consequently, we should break the string on the last
            slash, rather than the first. A cheap solution to this problem could be to reverse the
            string, applying <function>break</function>, and then reversing the results again. We
            will take a more sophisticated route, and write our own
            function:<programlisting>rsplit :: Eq a => a -> [a] -> ([a], [a])
rsplit sep l = let (ps, xs, _) = rsplit_ sep l in
               (ps, xs)

rsplit_ :: Eq a => a -> [a] -> ([a], [a], Bool)
rsplit_ sep = foldr (splitFun sep) ([], [], False)
    where splitFun sep e (px, xs, True) = (e:px, xs, True)
          splitFun sep e (px, xs, False)
                   | e == sep = (px, xs, True)
                   | otherwise = (px, e:xs, False)</programlisting></para>
        <para>The core business happens in the <function>rsplit_</function> function, it splits a
            list in the part before the last instance of <emphasis role="italic">sep</emphasis> (the
            prefix) and the part after (the suffix). It does this by folding over the input list
            from right to left. The accumulator is a tuple that holds the prefix list, the suffix
            list, and a <emphasis role="italic">Bool</emphasis> indicating whether the separator was
            encountered. The function provided to the fold acts upon this <emphasis role="italic"
                >Bool</emphasis>:<itemizedlist>
                <listitem>
                    <para>If the <emphasis role="italic">Bool</emphasis> is <emphasis role="italic"
                            >True</emphasis>, the separator was seen, and the current element is
                        added to the prefix list.</para>
                </listitem>
                <listitem>
                    <para>If the <emphasis role="italic">Bool</emphasis> is <emphasis role="italic"
                            >False</emphasis>, the separator was not seen yet. If the current
                        element is equal to the separator, the <emphasis role="italic"
                            >Bool</emphasis> is changed to <emphasis role="italic">True</emphasis>
                        to indicate that all remaining elements should be added to the prefix list.
                        Otherwise, the element is added to the suffix list.</para>
                </listitem>
            </itemizedlist><function>rsplit</function> is just a tiny wrapper around
                <function>rsplit_</function> that returns a binary tuple with just the prefix and
            suffix lists. The <function>rsplit</function> function works as
            intended:<screen>*Main> <userinput>rsplit '/' "the/AT"</userinput>
("the","AT")
*Main> <userinput>rsplit '/' "a/b/TEST"</userinput>
("a/b","TEST")</screen></para>
        <para>We are now able to get the necessary data out of a <emphasis role="italic"
                >String</emphasis> containing a token and a tag. We can simply construct a training
            instance by converting the
            tuple:<programlisting>toTrainingInstance :: String -> TrainingInstance
toTrainingInstance s = let (token, tag) = rsplit '/' s in
TrainingInstance token tag</programlisting></para>
        <!-- XXX - Read/Show is not really appropriate here, keep for later...
            <para>Rember that we let <emphasis
            role="italic">TrainingInstance</emphasis> derive from <emphasis role="italic"
            >Show</emphasis>? The typeclass <emphasis role="italic">Read</emphasis> is the
            converse of <emphasis role="italic">Show</emphasis> - data types implementing <emphasis
            role="italic">Read</emphasis> provide a <function>read</function>function that
            constructs an value from a <emphasis role="italic"
            >String</emphasis>:<screen>*Main> :type read
            read :: (Read a) => String -> a</screen></para>
            <para>To give an example, you can use <function>read</function> to read an <emphasis
            role="italic">Int</emphasis> or a <emphasis role="italic">Float</emphasis> from a
            <emphasis role="italic"
            >String</emphasis>:<screen>*Main> read "2" :: Int
            2
            *Main> read "2" :: Float
            2.0
            *Main> read "2.3" :: Float
            2.3</screen></para>
            <para>Wouldn't it be nice if we can convert <emphasis role="italic"
            >TrainingInstances</emphasis> from and to the corpus <emphasis role="italic"
            >String</emphasis> representation by implementing the <emphasis role="italic"
            >Show</emphasis> and <emphasis role="italic">Read</emphasis> typeclasses? With the
            functions that we have now, this turns out to be
            doable:<programlisting>data TrainingInstance = TrainingInstance Token Tag
            
            instance Show TrainingInstance where
            show i = let (TrainingInstance token tag) = i in
            token ++ "/" ++ tag
            
            instance Read TrainingInstance where
            readsPrec _ s = let (word, tag) = rsplit '/' s in
            [(TrainingInstance word tag, "")]</programlisting></para>
            <para>First, we removed the <emphasis role="italic">deriving</emphasis> clause from the
            definition of <emphasis role="italic">TrainingInstance</emphasis>, since we want to
            define what it means for <emphasis role="italic">TrainingInstance</emphasis> to be of
            the <emphasis role="italic">Show</emphasis> typeclass ourselves. To do this, we use the
            <emphasis role="italic">instance</emphasis> keyword to add <emphasis role="italic"
            >TrainingInstance</emphasis> as an instance of the <emphasis role="italic"
            >Show</emphasis> typeclass. We provide our own <function>show</function> function
            that simply concatenates the token and the tag, separated by a forward slash. The
            <emphasis role="italic">instance</emphasis> definition of <emphasis role="italic"
            >Read</emphasis> is a bit more complicated. It gives the opportunity to handle
            operator precedence (the first argument to <function>readsPrec</function>), and we are
            supposed to parse only the necessary part of the input.</para>
        -->
        <para>Why not see how we are doing, and get the ten first training instances of the Brown
            corpus?<screen>*Main> <userinput>h &lt;- IO.openFile "brown-pos-train.txt" IO.ReadMode</userinput>
*Main> <userinput>c &lt;- IO.hGetContents h</userinput>
*Main> <userinput>take 10 $ map toTrainingInstance $ words c</userinput>
[TrainingInstance "The" "AT",TrainingInstance "Fulton" "NP",
  TrainingInstance "County" "NN",TrainingInstance "Grand" "JJ",
  TrainingInstance "Jury" "NN",TrainingInstance "said" "VBD",
  TrainingInstance "Friday" "NR",TrainingInstance "an" "AT",
  TrainingInstance "investigation" "NN",TrainingInstance "of" "IN"]</screen></para>
        <para>Allright! That's indeed our corpus in beautified format. The next step is to traverse
            this corpus, registering for each word with which tag it occured (and how often). For
            this we write the <function>tokenTagFreq</function>
            function:<programlisting>import qualified Data.List as L
import qualified Data.Map as M

tokenTagFreqs :: [TrainingInstance] -> M.Map Token (M.Map Tag Int)
tokenTagFreqs = L.foldl' countWord M.empty
    where
      countWord m (TrainingInstance token tag) = 
          M.insertWith (countTag tag) token (M.singleton tag 1) m
      countTag tag old _ = M.insertWith
          (\newFreq oldFreq -> oldFreq + newFreq) tag 1 old</programlisting></para>
        <para>This function is very comparable to the <function>countElem</function> function we saw
            earlier, the primary difference being that we have to handle two levels of maps. Every
                <emphasis role="italic">Token</emphasis> in the first <emphasis role="italic"
                >Map</emphasis> is associated with a value that is itself a <emphasis role="italic"
                >Map</emphasis> that maps <emphasis role="italic">Tag</emphasis>s to frequencies
                (<emphasis role="italic">Int</emphasis>). If we have not seen a particular <emphasis
                role="italic">Token</emphasis> yet, we will insert it to the map with the <emphasis
                role="italic">Token</emphasis> as the key, the value is a map with just one
            key/value: the <emphasis role="italic">Tag</emphasis> associated with the token and a
            frequency of one. If the <emphasis role="italic">Token</emphasis> was seen before, we
            will update the frequency of the associated <emphasis role="italic">Tag</emphasis>,
            setting it to one, if the <emphasis role="italic">Tag</emphasis> was never seen before
            with this token.</para>
        <para>Let us test <emphasis role="italic">tokenTagFreqs</emphasis> on the first ten training
            instances as
            well:<screen>*Main> <userinput>h &lt;- IO.openFile "brown-pos-train.txt" IO.ReadMode</userinput>
*Main> <userinput>c &lt;- IO.hGetContents h</userinput>
*Main> <userinput>tokenTagFreqs $ take 10 $ map toTrainingInstance $ words c</userinput>
fromList [("County",fromList [("NN",1)]),("Friday",fromList [("NR",1)]),
  ("Fulton",fromList [("NP",1)]),("Grand",fromList [("JJ",1)]),
  ("Jury",fromList [("NN",1)]),("The",fromList [("AT",1)]),
  ("an",fromList [("AT",1)]),("investigation",fromList [("NN",1)]),
  ("of",fromList [("IN",1)]),("said",fromList [("VBD",1)])]</screen></para>
        <para>It seems to work, but we cannot be sure until we have seen duplicatesand ambiguous
            tokens. You may want to play a little with larger corpus samples or artificial training
            data to confirm that <function>tokenTagFreqs</function> works as intended.</para>
        <para>The next thing we need for our first part of speech tagger is use the map defined by
                <function>tokenTagFreqs</function> to find the most frequent tag for a word. This is
            a typical mapping situation: for each key/value pair in the <emphasis role="italic"
                >Map</emphasis>, we want to transform its value. The value was a <emphasis
                role="italic">Map</emphasis>, mapping <emphasis role="italic">Tag</emphasis> to
                <emphasis role="italic">Int</emphasis>, and we want the value to be a <emphasis
                role="italic">Tag</emphasis>, namely the most frequent <emphasis role="italic"
                >Tag</emphasis>. There is also a <function>map</function> functions for <emphasis
                role="italic"
            >Map</emphasis>:<screen>*Main> <userinput>:type Data.Map.map</userinput>
Data.Map.map :: (a -> b) -> M.Map k a -> M.Map k b</screen></para>
        <para><function>Data.Map.map</function> accepts some function to map every value in a
                <emphasis role="italic">Map</emphasis> to a new value. For getting the most frequent
                <emphasis role="italic">Tag</emphasis>, we have to fold over the inner map, storing
            the most frequent tag and its frequency in the accumulator. The <emphasis role="italic"
                >Data.Map</emphasis> module provides the <function>foldlWithKey</function> to fold
            over keys and
            values:<screen>*Main> <userinput>:type Data.Map.foldlWithKey</userinput>
Data.Map.foldlWithKey :: (b -> k -> a -> b) -> b -> M.Map k a -> b</screen></para>
        <para>This looks like the usual suspect, however, the folding function takes an additional
            parameter. The folding function has the current accumulator, the current key, and the
            associated value as its arguments. Using these building blocks, we can construct the
                <function>tokenMostFreqTag</function>
            function:<programlisting>tokenMostFreqTag :: M.Map Token (M.Map Tag Int) -> M.Map Token Tag
tokenMostFreqTag = M.map mostFreqTag
    where
      mostFreqTag = fst . M.foldlWithKey maxTag ("NIL", 0)
      maxTag acc@(maxTag, maxFreq) tag freq
                 | freq > maxFreq = (tag, freq)
                 | otherwise = acc</programlisting></para>
        <para>The main function body uses <function>mostFreqTag</function> to get the most frequent
            tag for each token. <function>mostFreqTag</function> folds over all tokens and
            frequencies of a map associated with a token. The initial value of the accumulator is
            the dummy tag 'NIL'. The <function>maxTag</function> function that is used in the fold
            will replace the accumulator with the current tag and its frequency if its frequency is
            higher than the frequency of the tag in the accumulator. Otherwise, the tag in the
            accumulator is more frequent, and the accumulator is retained. After folding, we have
            the pair of the most frequent tag, and its frequency. We use the
                <function>fst</function> function to get the first element of this pair.</para>
        <para>You can craft some examples to check whether <function>tokenMostFreqTag</function>
            works as intended. For
            example:<screen>*Main> <userinput>tokenMostFreqTag $ tokenTagFreqs [TrainingInstance "a" "A",
  TrainingInstance "a" "B", TrainingInstance "a" "A"]</userinput>
fromList [("a","A")]</screen></para>
        <para>Combining <function>tokenTagFreqs</function> and <function>tokenMostFreqTag</function>
            we can make a simple function to train our first tagging model from a list of <emphasis
                role="italic"
            >TrainingInstance</emphasis>:<programlisting>trainFreqTagger :: [TrainingInstance] -> M.Map Token Tag
trainFreqTagger = tokenMostFreqTag . tokenTagFreqs</programlisting></para>
        <para>Next up is the actual tagger: it simply looks up a token, returning the most frequent
            tag of a token. Since not all tags may be known, you may want to decide how to handle
            unknown tags. For now, we will just return the <emphasis role="italic">Maybe
                Tag</emphasis> type, allowing us to return <emphasis role="italic"
                >Nothing</emphasis> in the case we do not know how to tag a word. We will define the
            function <function>freqTagWord</function> as a simple wrapper around
                <function>Data.Map.lookup</function>:<programlisting>freqTagWord :: M.Map Token Tag -> Token -> Maybe Tag
freqTagWord m w = M.lookup w m</programlisting></para>
        <para>We can now train our model from the Brown corpus, and tag some
            sentences:<screen>*Main> <userinput>h &lt;- IO.openFile "brown-pos-train.txt" IO.ReadMode</userinput>
*Main> <userinput>c &lt;- IO.hGetContents h</userinput>
*Main> <userinput>let model = trainFreqTagger $ map toTrainingInstance $ words c</userinput>
*Main> <userinput>map (freqTagWord model) ["The","cat","is","on","the","mat","."]</userinput>
[Just "AT",Just "NN",Just "BEZ",Just "IN",Just "AT",Just "NN",Just "."]
*Main> <userinput>map (freqTagWord model) ["That's","right",",","the","mascara",
  "snake",".","Fast","and","bulbous",".","Also","a","tinned","teardrop","."]</userinput>
[Just "DT+BEZ",Just "QL",Just ",",Just "AT",Just "NN",Just "NN",Just ".",
  Nothing,Just "CC",Nothing,Just ".",Just "RB",Just "AT",Nothing,
  Just "NN",Just "."]</screen></para>
        <para>Isn't that NLP for the working programmer? Not only did you learn about POS tagging,
            you built your own first POS tagger in just a few lines of Haskell code. In the next
            section we will be a bit more scientific, and focus on evaluation of taggers.</para>
    </sect1>
    <sect1 xml:id="sec-tagging-evaluation">
        <title>Evaluation</title>
        <para>Now that you wrote your first tagger, the question is how well it work. Not only to
            show it off to your colleague (it will do relatively well), but also to be able to see
            how future changes impact the performance of the tagger. To check the performance of the
            tagger, we will use an evaluation corpus. You should never evaluate a natural language
            processing component on the training data, because it is easy to perform well on seen
            data. Suppose that you wrote a tagger that just remembered the training corpus exactly.
            This tagger would tag every word correctly, but it will behave badly on unseen
            data.</para>
        <para>For evaluating our taggers, we will use another set of sentences from the Brown
            corpus. These annotated sentences are provided in
                <filename>brown-pos-test.txt</filename>. Since file has the same format as
                <filename>brown-pos-train.txt</filename>, it can also be read as a list of <emphasis
                role="italic">TrainingInstance</emphasis>.</para>
        <para>To evaluate a POS tagger, we will write a function that takes a tagging function
                (<emphasis role="italic">word -> Maybe Tag</emphasis>) as its first argument and a
            training corpus as its second argument. It should then return a tuple with the total
            number of tokens in the corpus, the number of tokens that were tagged correctly, and the
            number of tokens for which the tagger did not provide an analysis (returned <emphasis
                role="italic">Nothing</emphasis>). This is the <function>evalTagger</function>
            function:</para>
        <programlisting>evalTagger tagFun = L.foldl' eval (0, 0, 0)
    where
      eval (n, c, u) (TrainingInstance token correctTag) =
          case tagFun token of
            Just tag -> if tag == correctTag then
                             (n+1, c+1, u)
                         else
                             (n+1, c, u)
            Nothing  -> (n+1, c, u+1)</programlisting>
        <para>The function is pretty simple, it folds over all instances in the evaluation data. The
            counts are incremented in the following manner:<itemizedlist>
                <listitem>
                    <para>If the tagger returned a tag for the current token, we have two options:<itemizedlist>
                            <listitem>
                                <para>The tagger picked the correct tag. We increment the number of
                                    tokens and the number of correct tags by one.</para>
                            </listitem>
                            <listitem>
                                <para>The tagger picked an incorrect tag. We only increment the
                                    number of tokens by one.</para>
                            </listitem>
                        </itemizedlist></para>
                </listitem>
                <listitem>
                    <para>The tagger returned no tag for the current token. We increment the number
                        of tokens and the number of untagged tokens by one.</para>
                </listitem>
            </itemizedlist></para>
        <para>Time to evaluate your first tagger!</para>
        <screen>*Main> <userinput>h &lt;- IO.openFile "brown-pos-train.txt" IO.ReadMode</userinput>
*Main> <userinput>c &lt;- IO.hGetContents h</userinput>
*Main> <userinput>let model = trainFreqTagger $ map toTrainingInstance $ words c</userinput>
*Main> <userinput>i &lt;- IO.openFile "brown-pos-test.txt" IO.ReadMode</userinput>
*Main> <userinput>d &lt;- IO.hGetContents i</userinput>
*Main> <userinput>evalTagger (freqTagWord model) $ map toTrainingInstance $ words d</userinput>
(272901,235402,11536)</screen>
        <para>Those are quite impressive numbers for a first try, <emphasis role="italic">235402 /
                272901 * 100% = 86.26%</emphasis> of the tokens were tagged and tagged correctly. Of
            the remaining 13.74% of the tokens, <emphasis role="italic">11536 / 272901 * 100% =
                4.23%</emphasis> of the words were not known. This means that we tagged <emphasis
                role="italic">235402 / (272901 - 11536) * 100% = 90.07%</emphasis> of the words
            known to our model correctly. </para>
    </sect1>
</chapter>
